{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = sc.textFile('millionsong.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "df = raw_data.map(lambda x: x.split(\",\")).map(lambda x: LabeledPoint(x[0],x[1:])).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|MAX(label)|MIN(label)|\n",
      "+----------+----------+\n",
      "|    2011.0|    1922.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('MAX(label)','MIN(label)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=79.0, features=DenseVector([0.8841, 0.6105, 0.6005, 0.4747, 0.2472, 0.3573, 0.3441, 0.3396, 0.6009, 0.4257, 0.6049, 0.4192]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "parsed_df = df.select(col('label')-1922, 'features')\\\n",
    "              .withColumnRenamed(\"(label - 1922)\",'label')\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = parsed_df.randomSplit([0.8,0.1,0.1])\n",
    "\n",
    "train_df.cache() \n",
    "val_df.cache() \n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg = test_df.agg({\"label\":\"mean\"}).map(lambda x: x[0]).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test RMSE is equal to 21.500234008\n"
     ]
    }
   ],
   "source": [
    "#baseline model - use average to predict\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "baseline_pred_label_df = train_df.select('label').withColumn('prediction',lit(avg))\n",
    "\n",
    "print \"Baseline Test RMSE is equal to %s\" %(evaluator.evaluate(baseline_pred_label_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Descent by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "def calc_RMSE(dataset):\n",
    "    \"\"\"Calculates the root mean squared error for an dataset of (prediction, label) tuples.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame of (float, float)): A `DataFrame` consisting of (prediction, label) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "#    evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "    return evaluator.evaluate(dataset)\n",
    "\n",
    "def gradient_summand(weights, lp):\n",
    "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\"\"\"\n",
    "    summand = DenseVector((DenseVector.dot(lp.features,weights) - lp.label)*lp.features)\n",
    "    return summand\n",
    "\n",
    "def get_labeled_prediction(weights, observation):\n",
    "    \"\"\"Calculates predictions given a tuple of (labeledpoint,features) \n",
    "       and returns a (prediction, label) tuple.\"\"\"\n",
    "    \n",
    "    prediction = float(DenseVector.dot(DenseVector(weights),observation.features))\n",
    "    label = float(observation.label)\n",
    "    \n",
    "    return prediction,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 8.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = len(train_df.first().features)\n",
    "w = np.zeros(d)\n",
    "train_df.map(lambda x: get_labeled_prediction(w,x)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-1.3589, -2.7773, -2.4829, -1.4645, -2.5551, -4.9228, -1.8748, -5.2439, -2.4979, -4.9767, -2.9213, -3.2111])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.map(lambda x: gradient_summand(w,x)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 25.77262172,  23.83357464,  -3.92820735,   8.6583658 ,\n",
       "          6.12917634,  -9.18378568,  18.50990266,   2.15926399,\n",
       "          9.78004183,   5.13518291,  11.92855951,   1.96051564]),\n",
       " array([  57.96525775,  105.26802754,  111.15816127,   77.13591876,\n",
       "          39.55728551,   22.76245899,   20.34147179,   20.1727166 ,\n",
       "          20.10011465,   20.03379812,   19.97199537,   19.91405699,\n",
       "          19.85947377,   19.80783741,   19.75881468,   19.71212947,\n",
       "          19.66755003,   19.62487964,   19.58394962,   19.54461411,\n",
       "          19.50674599,   19.47023365,   19.43497852,   19.40089304,\n",
       "          19.36789901,   19.33592627,   19.3049116 ,   19.27479777,\n",
       "          19.24553285,   19.21706946,   19.18936433,   19.16237775,\n",
       "          19.13607322,   19.11041708,   19.08537824,   19.06092786,\n",
       "          19.03703921,   19.01368739,   18.99084921,   18.968503  ,\n",
       "          18.94662851,   18.92520674,   18.90421989,   18.88365121,\n",
       "          18.86348493,   18.84370622,   18.82430104,   18.80525616,\n",
       "          18.78655904,   18.76819784,   18.75016129,   18.73243872,\n",
       "          18.71501999,   18.69789546,   18.68105595,   18.66449271,\n",
       "          18.64819741,   18.63216208,   18.61637913,   18.6008413 ,\n",
       "          18.58554164,   18.57047351,   18.55563052,   18.54100658,\n",
       "          18.52659583,   18.51239266,   18.49839166,   18.48458765,\n",
       "          18.47097565,   18.45755087,   18.44430868,   18.43124464,\n",
       "          18.41835447,   18.40563404,   18.39307937,   18.38068662,\n",
       "          18.36845208,   18.35637217,   18.34444343,   18.33266251,\n",
       "          18.32102618,   18.30953132,   18.29817489,   18.28695396,\n",
       "          18.27586569,   18.26490734,   18.25407624,   18.2433698 ,\n",
       "          18.23278551,   18.22232096,   18.21197377,   18.20174165,\n",
       "          18.19162239,   18.18161381,   18.17171383,   18.16192039,\n",
       "          18.15223152,   18.14264529,   18.13315981,   18.12377327]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linreg_gradient_descent(train_data, num_iters):\n",
    "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
    "\n",
    "    Returns a tuple of (weights, training errors).  Weights will be the\n",
    "            final weights (one weight per feature) for the model, and training errors will contain\n",
    "            an error (RMSE) for each iteration of the algorithm.\n",
    "    \"\"\"\n",
    "    # The length of the training data\n",
    "    n = train_data.count()\n",
    "    # The number of features in the training data\n",
    "    d = len(train_data.first().features)\n",
    "    w = np.zeros(d)\n",
    "    alpha = 1.0\n",
    "    # We will compute and store the training error after each iteration\n",
    "    error_train = np.zeros(num_iters)\n",
    "    for i in range(num_iters):\n",
    "        preds_and_labels_train = train_data.map(lambda x: get_labeled_prediction(w,x))\n",
    "        preds_and_labels_train_df = preds_and_labels_train.toDF([\"prediction\", \"label\"])\n",
    "        error_train[i] = calc_RMSE(preds_and_labels_train_df)\n",
    "\n",
    "        # Calculate the `gradient`.  Make use of the `gradient_summand` function you wrote in (3a).\n",
    "        # Note that `gradient` should be a `DenseVector` of length `d`.\n",
    "        gradient = train_data.map(lambda x: gradient_summand(w,x)).sum()\n",
    "\n",
    "        # Update the weights\n",
    "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
    "        w = w - alpha_i * gradient\n",
    "        \n",
    "    return w, error_train\n",
    "    \n",
    "\n",
    "linreg_gradient_descent(train_df, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train the model\n",
    "#### Now let's train a linear regression model on all of our training data and evaluate its accuracy on the validation set.\n",
    "#### Note that the test set will not be used here. If we evaluated the model on the test set, we would bias our final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:\n",
      "\tBaseline = 54.016\n",
      "\tLR0 = 18.695\n"
     ]
    }
   ],
   "source": [
    "num_iters = 50\n",
    "weights_LR0, error_train_LR0 = linreg_gradient_descent(train_df,num_iters)\n",
    "\n",
    "preds_and_labels = (val_df\n",
    "                      .map(lambda x: get_labeled_prediction(weights_LR0,x)))\n",
    "preds_and_labels_df = sqlContext.createDataFrame(preds_and_labels, [\"prediction\", \"label\"])\n",
    "rmse_val_LR0 = calc_RMSE(preds_and_labels_df)\n",
    "\n",
    "print 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(avg,\n",
    "                                                                       rmse_val_LR0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib implemenatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24.363862651,24.912341236,-67.5971290696,56.9051814471,-10.6287251479,-52.0090410333,33.0080849511,-22.2838782225,2.46575768152,-2.65959623067,-11.9921603324,-11.2864888329] 64.7416745647\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "# Values to use when training the linear regression model\n",
    "\n",
    "num_iters = 500  # iterations\n",
    "reg = 1e-1  # regParam\n",
    "alpha = .2  # elasticNetParam\n",
    "use_intercept = True  # intercept\n",
    "\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "lin_reg = LinearRegression(maxIter=num_iters, regParam=reg, \n",
    "                           elasticNetParam=0.1, fitIntercept=True)\n",
    "first_model = lin_reg.fit(train_df)\n",
    "\n",
    "# coeffsLR1 stores the model coefficients; interceptLR1 stores the model intercept\n",
    "coeffs_LR1 = first_model.coefficients\n",
    "intercept_LR1 = first_model.intercept\n",
    "print coeffs_LR1, intercept_LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark16/1.6.2/libexec/python/pyspark/ml/regression.py:123: UserWarning: weights is deprecated. Use coefficients instead.\n",
      "  warnings.warn(\"weights is deprecated. Use coefficients instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>14.903245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>15.116023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>17.767340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>19.693845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>33.519425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>9.911329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>24.198499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>28.875068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>30.121777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>22.203674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  prediction\n",
       "0      8   14.903245\n",
       "1      8   15.116023\n",
       "2      8   17.767340\n",
       "3     11   19.693845\n",
       "4     13   33.519425\n",
       "5     19    9.911329\n",
       "6     19   24.198499\n",
       "7     19   28.875068\n",
       "8     19   30.121777\n",
       "9     20   22.203674"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = first_model.transform(train_df)\n",
    "pred.select('label','prediction').toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "validation = first_model.transform(val_df).select('prediction','label')\n",
    "rmse_val_LR1 = evaluator.evaluate(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.0157232704 18.7501612875 15.873525187\n"
     ]
    }
   ],
   "source": [
    "print avg, rmse_val_LR0, rmse_val_LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'1.6.2'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
