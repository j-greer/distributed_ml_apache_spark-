{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_data = sc.textFile('/tmp/millionsong.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'2001.0,0.884123733793,0.610454259079,0.600498416968,0.474669212493,0.247232680947,0.357306088914,0.344136412234,0.339641227335,0.600858840135,0.425704689024,0.60491501652,0.419193351817'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "df = raw_data.map(lambda x: x.split(\",\")).map(lambda x: LabeledPoint(x[0],x[1:])).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|MAX(label)|MIN(label)|\n",
      "+----------+----------+\n",
      "|    2011.0|    1922.0|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr('MAX(label)','MIN(label)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=79.0, features=DenseVector([0.8841, 0.6105, 0.6005, 0.4747, 0.2472, 0.3573, 0.3441, 0.3396, 0.6009, 0.4257, 0.6049, 0.4192]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "parsed_df = df.select(col('label')-1922, 'features')\\\n",
    "              .withColumnRenamed(\"(label - 1922)\",'label')\n",
    "parsed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = parsed_df.randomSplit([0.8,0.1,0.1])\n",
    "\n",
    "train_df.cache() \n",
    "val_df.cache() \n",
    "test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg = test_df.agg({\"label\":\"mean\"}).map(lambda x: x[0]).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test RMSE is equal to 21.4410420021\n"
     ]
    }
   ],
   "source": [
    "#baseline model - use average to predict\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "\n",
    "baseline_pred_label_df = train_df.select('label').withColumn('prediction',lit(avg))\n",
    "\n",
    "print \"Baseline Test RMSE is equal to %s\" %(evaluator.evaluate(baseline_pred_label_df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Gradient Descent by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "def calc_RMSE(dataset):\n",
    "    \"\"\"Calculates the root mean squared error for an dataset of (prediction, label) tuples.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame of (float, float)): A `DataFrame` consisting of (prediction, label) tuples.\n",
    "\n",
    "    Returns:\n",
    "        float: The square root of the mean of the squared errors.\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(predictionCol=\"prediction\")\n",
    "    return evaluator.evaluate(dataset)\n",
    "\n",
    "def gradient_summand(weights, lp):\n",
    "    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\"\"\"\n",
    "    summand = DenseVector((DenseVector.dot(lp.features,weights) - lp.label)*lp.features)\n",
    "    return summand\n",
    "\n",
    "def get_labeled_prediction(weights, observation):\n",
    "    \"\"\"Calculates predictions given a tuple of (labeledpoint,features) \n",
    "       and returns a (prediction, label) tuple.\"\"\"\n",
    "    \n",
    "    prediction = float(DenseVector.dot(DenseVector(weights),observation.features))\n",
    "    label = float(observation.label)\n",
    "    \n",
    "    return prediction,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 79.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = len(train_df.first().features)\n",
    "w = np.zeros(d)\n",
    "train_df.map(lambda x: get_labeled_prediction(w,x)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-69.8458, -48.2259, -47.4394, -37.4989, -19.5314, -28.2272, -27.1868, -26.8317, -47.4678, -33.6307, -47.7883, -33.1163])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.map(lambda x: gradient_summand(w,x)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 22.48848811,  20.35340451,  -0.45991637,   8.18300814,\n",
       "          5.9616902 ,  -4.19283846,  15.4245702 ,   3.77217616,\n",
       "         10.33569038,   5.8586856 ,  10.95314623,   3.88831376]),\n",
       " array([  58.04966416,  105.51545512,  111.5299523 ,   77.48182423,\n",
       "          39.76244849,   22.84191665,   20.39213111,   20.22514401,\n",
       "          20.15589784,   20.09270968,   20.0338182 ,   19.97860503,\n",
       "          19.92658539,   19.87737057,   19.83064333,   19.78614082,\n",
       "          19.74364243,   19.70296088,   19.66393562,   19.62642781,\n",
       "          19.59031642,   19.55549523,   19.52187041,   19.48935863,\n",
       "          19.45788545,   19.42738409,   19.39779439,   19.36906188,\n",
       "          19.34113712,   19.31397504,   19.28753445,   19.26177756,\n",
       "          19.23666964,   19.21217865,   19.188275  ,   19.16493127,\n",
       "          19.14212199,   19.11982349,   19.09801369,   19.07667199,\n",
       "          19.05577909,   19.03531695,   19.0152686 ,   18.99561812,\n",
       "          18.97635051,   18.95745163,   18.93890816,   18.92070749,\n",
       "          18.9028377 ,   18.88528752]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linreg_gradient_descent(train_data, num_iters):\n",
    "    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n",
    "\n",
    "    Returns a tuple of (weights, training errors).  Weights will be the\n",
    "            final weights (one weight per feature) for the model, and training errors will contain\n",
    "            an error (RMSE) for each iteration of the algorithm.\n",
    "    \"\"\"\n",
    "    # The length of the training data\n",
    "    n = train_data.count()\n",
    "    # The number of features in the training data\n",
    "    d = len(train_data.first().features)\n",
    "    w = np.zeros(d)\n",
    "    alpha = 1.0\n",
    "    # We will compute and store the training error after each iteration\n",
    "    error_train = np.zeros(num_iters)\n",
    "    for i in range(num_iters):\n",
    "        preds_and_labels_train = train_data.map(lambda x: get_labeled_prediction(w,x))\n",
    "        preds_and_labels_train_df = preds_and_labels_train.toDF([\"prediction\", \"label\"])\n",
    "        error_train[i] = calc_RMSE(preds_and_labels_train_df)\n",
    "\n",
    "        # Calculate the `gradient`.  Make use of the `gradient_summand` function you wrote in (3a).\n",
    "        # Note that `gradient` should be a `DenseVector` of length `d`.\n",
    "        gradient = train_data.map(lambda x: gradient_summand(w,x)).sum()\n",
    "\n",
    "        # Update the weights\n",
    "        alpha_i = alpha / (n * np.sqrt(i+1))\n",
    "        w = w - alpha_i * gradient\n",
    "        \n",
    "    return w, error_train\n",
    "    \n",
    "\n",
    "linreg_gradient_descent(train_df, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Train the model\n",
    "#### Now let's train a linear regression model on all of our training data and evaluate its accuracy on the validation set.\n",
    "#### Note that the test set will not be used here. If we evaluated the model on the test set, we would bias our final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE:\n",
      "\tBaseline = 53.898\n",
      "\tLR0 = 18.868\n"
     ]
    }
   ],
   "source": [
    "num_iters = 50\n",
    "weights_LR0, error_train_LR0 = linreg_gradient_descent(train_df,num_iters)\n",
    "\n",
    "preds_and_labels = (train_df\n",
    "                      .map(lambda x: get_labeled_prediction(weights_LR0,x)))\n",
    "preds_and_labels_df = sqlContext.createDataFrame(preds_and_labels, [\"prediction\", \"label\"])\n",
    "rmse_val_LR0 = calc_RMSE(preds_and_labels_df)\n",
    "\n",
    "print 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(avg,\n",
    "                                                                       rmse_val_LR0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib implemenatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.1415172278,33.5315246311,-59.5911663705,23.772992963,13.1904337511,-21.8018197814,72.1026876964,-9.76595898769,26.9943498558,-0.869818673973,21.4228842016,-18.2569617806] 0.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "# Values to use when training the linear regression model\n",
    "\n",
    "num_iters = 500  # iterations\n",
    "reg = 1e-1  # regParam\n",
    "alpha = .2  # elasticNetParam\n",
    "use_intercept = True  # intercept\n",
    "\n",
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "lin_reg = LinearRegression(maxIter=num_iters, regParam=reg, \n",
    "                           elasticNetParam=0.1, fitIntercept= False)\n",
    "first_model = lin_reg.fit(train_df)\n",
    "\n",
    "# coeffsLR1 stores the model coefficients; interceptLR1 stores the model intercept\n",
    "coeffs_LR1 = first_model.coefficients\n",
    "intercept_LR1 = first_model.intercept\n",
    "print coeffs_LR1, intercept_LR1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
